

<!--
theme:gradient
class:blue
paginate:true
-->

Part One
**深度学习技术的发展与优势**
1958年，**感知器模型(Rosenblatt)** 的提出，可以进行**二分类任务**的简单神经网络，是早期的深度学习雏形。`y = f(w * x + b)`
1986年，David Rumelhart、Geoffrey Hinton、Ronald Williams等人发表了一篇重要的论文(Rumelhart等)，系统地描述和推广了**反向传播算法**，使得训练多层神经网络成为可能，标志着深度学习技术的一次重要进展。
1990-2000年， 尽管有了反向传播算法，但由于数据和计算资源的不足，神经网络的应用依然有限，研究进入低谷期。
2012年，**AlexNet**(Krizhevsky)在ImageNet竞赛中取得了重大突破，标志着**深度学习时代**的正式到来。随后，深度学习在图像识别、自然语言处理、语音识别等领域都取得了显著的进提出了展。

---
Part Two
**已有数据产品面向应急救灾所面临的难题**
（1）***开源项目的数据质量较难保证，且数据分布并不均衡***。以OSM数据为例。影响OSM空间数据质量的因素众多，***OSM空间数据获取、处理以及表达应用***都会引发数据质量问题。对于具有***众源特征***的OSM数据，志愿者的空间认知水平和数据获取方法的不确定性是影响其数据质量问题的关键因素(张宏奎，2022)。此外，由于***国内向OSM提供数据的用户不多***，中国的道路数据量也相对偏少。

（2）**国内商业数据的更新能力弱，易用性低**。像高德和百度地图等国内商业道路数据，尽管数据质量相对较高，但由于其更新依赖于***传统采集方式***，一些城市仍存在道路更新滞后、实时数据准确性低的问题，很难服务于灾害应急。此外在使用这类商业地图产品时，其数据有严格的使用条款和授权要求，未经授权的使用会***面临法律风险***。

（3）**国外数据缺少中国道路信息**。由于我国对于地理信息的保密要求较高，道路等基础测绘数据一般很少向国外公开。因此国外商业数据对中国大陆地区的覆盖能力十分有限，很难服务于国内的应用需求。

---
Part Three
**研究内容**
***克服OSM数据存在的问题***

1.OSM中***道路等级***的定义和标注标准因地区而异
2.OSM 数据与遥感影像集成时，也会面临影像分辨率和质量不统一的问题
3.不同场景下的道路在***材质、宽度、布局和几何特征***上存在显著差异
4.在森林区域道路由于紧邻自然环境，容易***受到树木、灌木等植被的遮挡***，导致在遥感影像中辨识度较低
5.城市区域的道路网络相对密集，拥有较为**复杂的布局和多样的道路等级***，**且常被建筑物、立交桥、行道树等遮挡**
6.农村道路相较于城市更为**狭窄**，材质多为***土路或简易铺装，且道路网络稀疏***。这类道路的特征微弱


***研究重点***
1.进一步提高OSM数据的样本价值
综合多源数据，结合模型微调、迁移学习等技术，进一步提升道路提取的鲁棒性和泛化性，2.这也正是本项目期望实现的核心目标。


---
Part Four


---

![[Pasted image 20241031092550.png]]这个 `SwinT_OAM` 类定义了一个语义分割网络的架构，结合了 Swin Transformer 作为主干网络（backbone）和一些自定义的解码器和去除模块（erase module）。整个模型的设计思想是利用 Swin Transformer 提取特征，然后通过多层解码器和转置卷积恢复到原始分辨率，以实现精细的特征分割。以下是模型的结构和各个模块的作用说明：

### 1. 模型初始化 (`__init__`)

#### 主要模块

- **filters**: 设定特征提取的不同层的通道数。`filters = [96, 192, 384, 768]` 表示模型在不同特征提取阶段的通道数逐步增加，这是一种常见的设计，随着网络的加深通道数增多，以捕捉更多高级特征。
    
- **backboon (Swin Transformer)**: 使用 Swin Transformer 作为特征提取的主干网络（`backbone`），负责从输入图像中提取多层次的特征。这些特征会在网络的后续层中进一步处理。`self.backboon.init_weights()` 指定了加载的预训练权重路径，可能是经过 ImageNet 数据集预训练的 Swin Transformer 模型。
    
- **decoder**: 解码器模块，用于将 Swin Transformer 输出的多层特征（`e1, e2, e3, e4`）组合起来，以生成更精细的分割结果。`build_decoder(filters)` 创建的解码器能够处理不同层次的特征并将其组合，以获取高分辨率的输出。
    
- **erase**: 去除模块，负责处理并去除一些无关信息的特征。`build_erase(in_channel=int(filters[0]/4), erase_channel=int(filters[0]/4))` 设置了去除模块的输入通道和去除通道数，使其适配解码后的特征图。
    
- **deconv (转置卷积层)**: 该部分使用了转置卷积（deconvolution 或 transpose convolution）和普通卷积的组合，主要作用是将解码器输出的低分辨率特征图逐渐恢复到更高分辨率，以便生成更精细的分割结果。该模块包含以下层：
    
    - 转置卷积层：恢复特征图的分辨率。
    - 批归一化（BatchNorm2d）和激活函数 ReLU，规范化和激活特征图。
    - 普通卷积：调整通道数。
- **finalconv**: 最后的卷积层，用于将解码的特征图变成单通道的分割图。`self.finalconv = nn.Conv2d(int(filters[0]/4), 1, 1)` 将通道数缩减到 1，输出一个二值分割图。
    

### 2. 前向传播 (`forward`)

前向传播定义了模型接收输入图像并生成分割图的过程。

1. **特征提取**:
    
    python
    
    复制代码
    
    `x4 = self.backboon(x)`
    
    输入图像 `x` 通过 Swin Transformer (`self.backboon`) 提取多层特征 `x4`。`x4` 包含从浅层到深层的特征图 `[e1, e2, e3, e4]`。
    
2. **特征组合与解码**:
    
    python
    
    复制代码
    
    `x = self.decoder(e1, e2, e3, e4)`
    
    Swin Transformer 提取的多层特征 `e1`、`e2`、`e3` 和 `e4` 经过解码器模块组合，产生一个融合了不同层次信息的特征图 `x`。
    
3. **去除无关信息**:
    
    python
    
    复制代码
    
    `x1 = self.erase(x)`
    
    将解码器的输出 `x` 传递到去除模块 (`erase`)，得到去除了某些无关信息的特征图 `x1`。
    
4. **恢复分辨率**:
    
    python
    
    复制代码
    
    `x2 = self.deconv(x)`
    
    转置卷积层 `deconv` 将解码后的低分辨率特征图 `x` 逐步恢复到更高分辨率，得到 `x2`。
    
5. **组合特征**:
    
    python
    
    复制代码
    
    `x = x1 + x2`
    
    将去除模块输出的 `x1` 与转置卷积层的输出 `x2` 相加，得到最终的高分辨率特征图 `x`。
    
6. **生成分割图**:
    
    python
    
    复制代码
    
    `x = self.finalconv(x)`
    
    最后，通过一个 `1x1` 卷积层 `finalconv`，将 `x` 的通道数降为 1，生成一个单通道的分割图。
    
7. **激活函数**:
    
    python
    
    复制代码
    
    `return torch.sigmoid(x)`
    
    最终，对输出应用 Sigmoid 激活函数，将输出值限制在 `[0, 1]` 之间，适合于二值分割任务。
    

### 总结

- **Swin Transformer** 作为主干网络提取不同层次的特征。
- **解码器和去除模块** 对特征进行处理，去除无关信息。
- **转置卷积** 恢复特征图的分辨率。
- **最终卷积** 生成二值分割图，输出掩码图像。

这种架构适合于语义分割任务，因为它能够有效利用 Transformer 和卷积层的优势，通过提取的多尺度特征和高分辨率重构，实现准确的分割。